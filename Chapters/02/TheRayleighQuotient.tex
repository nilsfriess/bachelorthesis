\section{The Rayleigh Quotient}\label{sec:rqi:rq}
In Chapter~\ref{chapter:intro} we briefly introduced iterative methods
for computing eigenpairs. In essence, RQI is shifted inverse iteration
where the shift is replaced by the \emph{Rayleigh quotient} at each
step. As we will see, the Rayleigh Quotient can be used to obtain good
estimates of an eigenvalue given an approximation of an eigenvector.

\begin{definition}[Rayleigh Quotient]
  Let $\mat{A} \in \C^{n \times n}$. The mapping
  \begin{equation*}
    \rq_{\mat{A}} : \C^n \setminus \{\vec{0}\} \rightarrow \C, \qquad
    \vec{x} \mapsto \frac{\vec{x}^\herm \mat{A} \vec{x}}{\vec{x}^\herm \vec{x}}
  \end{equation*}
  is called the \emph{Rayleigh quotient}\footnote{Other notations that
    are popular in the literature include
    $R_{\mat{A}}(\vec{x}),\ R(\mat{A}, \vec{x}),\
    r_{\mat{A}}(\vec{x}),\ \sigma_{\mat{A}}(\vec{x}))$ or
    $\uprho_{\mat{A}}(\vec{x})$.}  corresponding to the matrix
  $\mat{A}$.
\end{definition}
Note that for real matrices, we have
\begin{equation*}
  \rq_{\mat{A}}(\vec{x}) = \frac{\vec{x}^\tp \mat{A} \vec{x}}{\vec{x}^\tp \vec{x}}
\end{equation*}

We begin by discussing some basic facts.
\begin{lemma}%
  \label{lem:rq:properties}
  Let $\vec{x}\in \C^n \setminus \{ \vec{0} \}$,
  $0 \neq \alpha, \beta \in \C$ and $\mat{A} \in \C^{n \times n}$.
  \begin{enumerate}[label=(\roman*)]
  \item If $(\lambda, \vec{v})$ is an eigenpair of $\mat{A}$, then
    $\rq_{\mat{A}}(\vec{v}) = \lambda$.
  \item
    $\rq_{\beta \mat{A}}(\alpha \vec{x}) = \beta
    \rq_{\mat{A}}(\vec{x})$ \hfill (Homogeneity)

  \item
    $\rq_{\mat{A} - \alpha \mat{I}}(\vec{x}) = \rq_{\mat{A}}(\vec{x})
    - \alpha$ \hfill (Translation invariance)
  \end{enumerate}
\end{lemma}

\begin{proof}
  \begin{enumerate}[label=(\roman*)]
  \item We can write the Rayleigh Quotient as
    \begin{equation}
      \label{eq:rq:innerprod}
      \rq_{\mat{A}}(\vec{x}) = \frac{
        \langle \vec{x}, \mat{A} \vec{x}\rangle
      }{
        \langle \vec{x}, \vec{x} \rangle
      }\,,
    \end{equation}
    where $\langle \vec{x}, \vec{y} \rangle = \vec{x}^\herm \vec{y}$
    denotes the Euclidean inner product on $\C^n$. Due to the
    linearity in the second argument we obtain
    \begin{equation*}
      \rq_{\mat{A}}(\vec{v}) = \frac{
        \langle \vec{v}, \mat{A} \vec{v}\rangle
      }{
        \langle \vec{v}, \vec{v} \rangle
      }
      =
      \frac{
        \langle \vec{v}, \lambda \vec{v}\rangle
      }{
        \langle \vec{v}, \vec{v} \rangle
      }
      =
      \lambda \frac{
        \langle \vec{v}, \vec{v}\rangle
      }{
        \langle \vec{v}, \vec{v} \rangle
      }
      =
      \lambda\,.
    \end{equation*}
  \item By again writing the Rayleigh Quotient as
    in~\eqref{eq:rq:innerprod} and using the semi-linearity in the
    first and linearity in the second argument of the inner product,
    we obtain
    \begin{equation*}
      \rq_{\beta \mat{A}}(\alpha \vec{x}) = \frac{
        \langle \alpha \vec{x}, \beta \mat{A} (\alpha \vec{x} )\rangle
      }{
        \langle \alpha \vec{x}, \alpha \vec{x} \rangle
      }
      = \beta \frac{
        \overline{\alpha} \alpha \langle \vec{x}, \mat{A} \vec{x} \rangle
      }{
        \overline{\alpha} \alpha \langle\vec{x}, \vec{x} \rangle
      }
      =
      \beta \rq_{\mat{A}}(\vec{x})\,.
    \end{equation*}

  \item
    \[
      \rq_{\mat{A} - \alpha \mat{I}}(\vec{x}) = \frac{ \vec{x}^\herm (
        \mat{A} - \alpha \mat{I}) \vec{x} }{ \vec{x}^\herm \vec{x} } =
      \frac{ \vec{x}^\herm \mat{A} \vec{x} - \alpha \vec{x}^\herm
        \vec{x} }{ \vec{x}^\herm \vec{x} } = \rq_{\mat{A}}(\vec{x}) -
      \alpha \,.
    \]
  \end{enumerate}
\end{proof}

Altough the Rayleigh Quotient might look arbitrary at first sight, it
occurs naturally as the solution of a least squares minimisation
problem. First note that if $(\lambda, \vec{v})$ is an eigenpair of
$\mat{A}$, then
\begin{equation*}
  \norm{\mat{A} \vec{v} - \lambda \vec{v}}^2 = 0\,.
\end{equation*}
Now, suppose $\hat{\vec{v}}$ is an approximation for $\vec{v}$ and we
want to find the best approximation $\hat{\lambda}$ for $\lambda$ in
the sense that
\begin{equation*}
  \hat{\lambda} = \argmin_{\mu \in \C} \norm{\mat{A} \hat{\vec{v}} - \mu \hat{\vec{v}}}^2\,.
\end{equation*}
This is a linear least squares problem in $\mu$ with normal equations
(cf.~\cite[106]{demmel})
\begin{equation*}
  \left( \hat{\vec{v}}^\herm \hat{\vec{v}} \right) \mu = \hat{\vec{v}}^\herm \mat{A} \hat{\vec{v}}
\end{equation*}
and dividing by $\left( \hat{\vec{v}}^\herm \hat{\vec{v}} \right)$
yields
\begin{equation*}
  \mu = \frac{\hat{\vec{v}}^\herm \mat{A} \hat{\vec{v}}}{\left( \hat{\vec{v}}^\herm \hat{\vec{v}} \right)}
\end{equation*}

To see how good of an approximation the Rayleigh Quotient is we first
need the notion of an \emph{angle} between to vectors. This definition
will be also used later when analysing the convergence of RQI.

\begin{definition}[Angle]
  The \emph{angle} between two vectors
  $\vec{x}, \vec{y} \in \C^n \setminus \{ \vec{0} \}$ is defined as
  \begin{equation*}
    \angle(\vec{x}, \vec{y}) = \arccos \frac{
      \abs{\langle \vec{x}, \vec{y} \rangle}
    }{
      \norm{\vec{x}} \norm{\vec{y}}
    }\,.
  \end{equation*}
  Often, the following identites are convenient
  \begin{align*}
    \cos \angle(\vec{x}, \vec{y}) &= \frac{
                                    \abs{\langle \vec{x}, \vec{y} \rangle}
                                    }{
                                    \norm{\vec{x}} \norm{\vec{y}}
                                    }\,,\\
    \sin \angle(\vec{x}, \vec{y}) &\coloneqq
                                    \sqrt{1 - \cos^2 \angle(\vec{x}, \vec{y})}\,, \\
    \tan \angle(\vec{x}, \vec{y}) &\coloneqq
                                    \frac{
                                    \sin \angle(\vec{x}, \vec{y})
                                    }{
                                    \cos \angle(\vec{x}, \vec{y})
                                    }\,.
  \end{align*}
\end{definition}
According to Parlett the following result is the property to which
``the phenomenal convergence rate [of RQI] can be
attributed''~\cite[77]{Parlett1998}.

\begin{lemma}[Eigenvalue estimate]%
  \label{lem:rq:quadestimate}
  Let $\vec{x} \in \C^n$ be an approximation of an eigenvector
  $\vec{v}$ of a normal\footnote{A matrix $\mat{A}$ is said to be
    \emph{normal} if $\mat{A}^\herm \mat{A} = \mat{A}
    \mat{A}^\herm$. Note that for complex Hermitian (or real
    symmetric) matrices we have $\mat{A} = \mat{A}^{\herm}$, hence
    Hermitian (and thus symmetric) matrices are normal.} matrix
  $\mat{A}$ with corresponding eigenvalue $\lambda$. Then
  \begin{equation*}
    \abs{\rq_{\mat{A}}(\vec{x}) - \lambda}
    \le
    \norm{\mat{A} - \lambda \mat{I}} \sin^2 \angle(\vec{x}, \vec{v})
    \le
    \norm{\mat{A} - \lambda \mat{I}} {\left( \frac{
          \norm{\vec{x} - \alpha \vec{v}}
        }{
          \norm{\vec{x}}
        }\right)}^2 \quad \text{ for all } \alpha \in \C\,.
  \end{equation*}
\end{lemma}
\begin{proof}[The proof is given in Appendix~\ref{AppendixProofs}]
\end{proof}
This result is often paraphrased as ``the Rayleigh Quotient is a
\emph{quadratically accurate} estimate of an eigenvalue'' (see for
example~\cite[204]{trefethen1997}) and is often presented in the
following shorter form\todo{cite examples}
\begin{equation*}
  \abs{\rq_{\mat{A}}(\vec{x}) - \rq_{\mat{A}}(\vec{v})} = \mathcal{O}(\norm{\vec{x} - \vec{v}}^2)\,.
\end{equation*}
If $\mat{A}$ is non-normal, the Rayleigh quotient is still an estimate
of order one, \ie
\begin{equation*}
  \abs{\rq_{\mat{A}}(\vec{x}) - \rq_{\mat{A}}(\vec{v})} = \mathcal{O}(\norm{\vec{x} - \vec{v}})\,.
\end{equation*}
We now have a method that allows us to obtain an estimation of an
\emph{eigenvalue} from an \emph{eigenvector}. With the Shifted Inverse
Iteration (Algorithm~\ref{alg:sii}) we have the converse: a method for
obtaining an \emph{eigenvector} estimate from an \emph{eigenvalue}
estimate. Rayleigh Quotient Iteration is essentially a combination of
those two methods where each step consits of one step of Shifted
Inverse Iteration and the computation of the Rayleigh Quotient.

\begin{algorithm}[htbp]
  \DontPrintSemicolon%
  \KwData{Nonzero unit vector $\vec{x}^{(0)}$}
  $\mu^{(0)} \gets {\left(\vec{x}^{(0)}\right)}^\ast \mat{A} \vec{x}^{(0)}$ \;
  \For{$k = 1,2, \dotsc$ until convergence}{
    Solve ${\left( \mat{A} - \mu^{(k)} \mat{I}\right)} \vec{y}^{(k)} = \vec{x}^{(k-1)}$ for $\vec{y}^{(k)}$\;
    $\vec{x}^{(k)} \gets \vec{y}^{(k)} / \norm{\vec{y}^{(k)}}$\;
    $\mu^{(k)} \gets {\left(\vec{x}^{(k)}\right)}^\ast \mat{A} \vec{x}^{(k)}$ \;
  } 
  \caption{Rayleigh Quotient Iteration}\label{alg:rqi}
\end{algorithm}

We have yet to define what we mean by ``until convergence'' (cf. the
algorithms persented in Section~\ref{sec:iterative:algorithms}). Now
that we the defined the Rayleigh Quotient, we can define the following
stopping criterion. Run the iteration until
\begin{equation*}
  \norm{\vec{r}^{(k)}} = \norm{\mat{A}\vec{x}^{(k)} - \mu^{(k)} \vec{x}^{(k)}} < \mathtt{tol}\,,
\end{equation*}
where
$\vec{r}^{(k)} \coloneqq \mat{A}\vec{x}^{(k)} - \mu^{(k)}
\vec{x}^{(k)}$ is called the \emph{residual vector} and $\mathtt{tol}$
is a user-given error tolerance. Obviously, if for some $k$ the tuple
$(\mu^{(k)}, \vec{x}^{(k)})$ is an eigenpair we have
$\vec{r}^{(k)} = \vec{0}$. For approximate eigenpairs we expect a
small residual to imply small errors in these approximations. A
rigorous justfication\todo{Rewrite} is given
in~\cite[59\psqq]{saad2011}. Here, we give only some important results
without proof for the case when $\mat{A}$ is symmetric. A popular
result, usually referred to as the \emph{Bauer-Fike theorem} (see,
\eg~\cite[59]{saad2011}) states that there exists an eigenvalue
$\lambda$ of $\mat{A}$ such that
\begin{equation}
  \label{eq:bauer-fike}
  \abs{\lambda - \mu^{(k)}} \le \kappa(\mat{Q}) \norm{\vec{r}^{(k)}}\,,
\end{equation}
where $\mat{Q}$ is a matrix that transforms $\mat{A}$ into diagonal
form (\ie $\mat{Q}$ is such that $\mat{Q}^{-1}\mat{A}\mat{Q}$ is
diagonal) and
$\kappa(\mat{Q}) \coloneqq \norm{\mat{Q}}\norm{\mat{Q}^{(-1)}}$ is the
\emph{condition number} of $\mat{Q}$. Such a matrix exists due to the
\emph{spectral theorem}~\cite[Theorem 18 and Corollary,
p.~314]{hoffmanlinalg}. Since $\mat{A}$ is real and symmetric
$\mat{Q}$ is an \emph{orthogonal} matrix. In particular
$\norm{\mat{Q}} = \norm{\mat{Q}^{-1}} = 1$ and thus
\begin{equation*}
  \abs{\lambda - \mu^{(k)}} \le \norm{\vec{r}^{(k)}}\,.
\end{equation*}
Therefore, if the stopping criterion is fulfilled, we have
$\abs*{\lambda - \mu^{(k)}} < \mathtt{tol}$.  For the eigenvector one
can show~\cite[63]{saad2011} that the following bound holds
\begin{equation*}
  \sin \angle(\vec{x}^{(k)}, \vec{v}) \le \frac{
    \norm{\vec{r}^{(k)}}
  }{
    \delta
  }\,,
\end{equation*}
where $\vec{v}$ is an eigenvector associtated with $\lambda$ and
$\delta$ is the distance from $\mu^{(k)}$ to the rest of the spectrum,
\ie
\begin{equation*}
  \delta \coloneqq \min_i\, \{ \abs*{\mu^{(k)} - \lambda_i} \ : \ \lambda_i \neq \lambda \} \,.
\end{equation*}
These results hold if
$\mu^{(k)} = {(\vec{x}^{(k)})}^\ast \mat{A} {(\vec{x}^{(k)})}$
(Rayleigh Quotient).\todo{Stopping criteria in Power method and SIT}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../main"
%%% End:
