\section{The Rayleigh Quotient}
Recall the general problem: Given approximations of an eigenvector of
a symmetric matrix $\mat{A} = \mat{A}^\tp \in \R^{n \times n}$ we want
to compute the exact eigenvector and associated eigenvalue. In
Section~\ref{sec:iterative:algorithms} we briefly introduced iterative
methods for computing eigenpairs. In essence, RQI is shifted inverse
iteration where the shift is replaced by the \emph{Rayleigh quotient}
at each step.

\begin{definition}[Rayleigh Quotient]
  Let $\mat{A} \in \C^{n \times n}$. The mapping
  \[
    \rq_{\mat{A}} : \C^n \setminus \{\vec{0}\} \rightarrow \C, \qquad
    \vec{x} \mapsto \frac{\vec{x}^\herm \mat{A} \vec{x}}{\vec{x}^\herm
      \vec{x}}
  \]
  is called the \emph{Rayleigh quotient} corresponding to the matrix
  $\mat{A}$.
\end{definition}
Note that for real matrices, we have
\[
  \rq_{\mat{A}} : \R^n \setminus \{\vec{0}\} \rightarrow \R, \qquad
  \vec{x} \mapsto \frac{\vec{x}^\tp \mat{A} \vec{x}}{\vec{x}^\tp
    \vec{x}}
\]

We begin by discussing some basic facts.
\begin{lemma}%
  \label{lem:rq:properties}
  Let $\vec{x}\in \C^n \setminus \{ \vec{0} \}$,
  $0 \neq \alpha, \beta \in \C$ and $\mat{A} \in \C^{n \times n}$.
  \begin{enumerate}[label=(\roman*)]
  \item For an eigenpair $(\lambda, \vec{v})$ of $\mat{A}$ we have
    $\rq_{\mat{A}}(\vec{v}) = \lambda$.
  \item
    $\rq_{\beta \mat{A}}(\alpha \vec{x}) = \beta
    \rq_{\mat{A}}(\vec{x})$ \hfill (Homogenity)

  \item
    $\rq_{\mat{A} - \alpha \mat{I}}(\vec{x}) = \rq_{\mat{A}}(\vec{x})
    - \alpha$ \hfill (Translation invariance)
  \end{enumerate}
\end{lemma}

\begin{proof}
  \begin{enumerate}[label=(\roman*)]
  \item We can write the Rayleigh Quotient as
    \begin{equation}
      \label{eq:rq:innerprod}
      \rq_{\mat{A}}(\vec{x}) = \frac{
        \langle \vec{x}, \mat{A} \vec{x}\rangle
      }{
        \langle \vec{x}, \vec{x} \rangle
      }\,,
    \end{equation}
    where $\langle \vec{x}, \vec{y} \rangle = \vec{x}^\herm \vec{y}$
    denotes the Euclidean inner product on $\C^n$. Due to the
    linearity in the second argument we obtain
    \begin{equation*}
      \rq_{\mat{A}}(\vec{v}) = \frac{
        \langle \vec{v}, \mat{A} \vec{v}\rangle
      }{
        \langle \vec{v}, \vec{v} \rangle
      }
      =
      \frac{
        \langle \vec{v}, \lambda \vec{v}\rangle
      }{
        \langle \vec{v}, \vec{v} \rangle
      }
      =
      \lambda \frac{
        \langle \vec{v}, \vec{v}\rangle
      }{
        \langle \vec{v}, \vec{v} \rangle
      }
      =
      \lambda\,.
    \end{equation*}
  \item By again writing the Rayleigh Quotient as
    in~\eqref{eq:rq:innerprod} and using the semilinearity in the
    first and linearity in the second argument of the inner product,
    we obtain
    \begin{equation*}
      \rq_{\beta \mat{A}}(\alpha \vec{x}) = \frac{
        \langle \alpha \vec{x}, \beta \mat{A} (\alpha \vec{x} )\rangle
      }{
        \langle \alpha \vec{x}, \alpha \vec{x} \rangle
      }
      = \beta \frac{
        \overline{\alpha} \alpha \langle \vec{x}, \mat{A} \vec{x} \rangle
      }{
        \overline{\alpha} \alpha \langle\vec{x}, \vec{x} \rangle
      }
      =
      \beta \rq_{\mat{A}}(\vec{x})\,.
    \end{equation*}

  \item
    \[
      \rq_{\mat{A} - \alpha \mat{I}}(\vec{x}) = \frac{ \vec{x}^\herm (
        \mat{A} - \alpha \mat{I}) \vec{x} }{ \vec{x}^\herm \vec{x} } =
      \frac{ \vec{x}^\herm \mat{A} \vec{x} - \alpha \vec{x}^\herm
        \vec{x} }{ \vec{x}^\herm \vec{x} } = \rq_{\mat{A}}(\vec{x}) -
      \alpha \,.
    \]
  \end{enumerate}
\end{proof}

Altough the Rayleigh Quotient might look arbitrary at first sight, it
occurs naturally as the solution of a least squares minimisation
problem. First note that if $(\lambda, \vec{v})$ is an eigenpair of
$\mat{A}$, then
\begin{equation*}
  \norm{\mat{A} \vec{v} - \lambda \vec{v}}^2 = 0\,.
\end{equation*}
Now, suppose $\hat{\vec{v}}$ is an approximation for $\vec{v}$ and we
want to find the best approximation $\hat{\lambda}$ for $\lambda$ in
the sense that
\begin{equation*}
  \hat{\lambda} = \argmin_{\mu \in \C} \norm{\mat{A} \hat{\vec{v}} - \mu \hat{\vec{v}}}^2\,.
\end{equation*}
This is a linear least squares problem in $\mu$ with normal equations
(cf.~\cite[106]{demmel})
\begin{equation*}
  \left( \hat{\vec{v}}^\herm \hat{\vec{v}} \right) \mu = \hat{\vec{v}}^\herm \mat{A} \hat{\vec{v}}
\end{equation*}
and dividing by $\left( \hat{\vec{v}}^\herm \hat{\vec{v}} \right)$
yields
\begin{equation*}
  \mu = \frac{\hat{\vec{v}}^\herm \mat{A} \hat{\vec{v}}}{\left( \hat{\vec{v}}^\herm \hat{\vec{v}} \right)}
\end{equation*}

To see how good of an approximation the Rayleigh Quotient is we first
need the notion of an \emph{angle} between to vectors. This definition
will be also used later when analysing the convergence of RQI.

\begin{definition}[Angle]
  The \emph{angle} between two vectors
  $\vec{x}, \vec{y} \in \C^n \setminus \{ \vec{0} \}$ is defined as
  \begin{equation*}
    \angle(\vec{x}, \vec{y}) = \arccos \frac{
      \abs{\langle \vec{x}, \vec{y} \rangle}
    }{
      \norm{\vec{x}} \norm{\vec{y}}
    }\,.
  \end{equation*}
  Often, the following identites are convenient
  \begin{align*}
    \cos \angle(\vec{x}, \vec{y}) &= \frac{
                                    \abs{\langle \vec{x}, \vec{y} \rangle}
                                    }{
                                    \norm{\vec{x}} \norm{\vec{y}}
                                    }\,,\\
    \sin \angle(\vec{x}, \vec{y}) &\coloneqq
                                    \sqrt{1 - \cos^2 \angle(\vec{x}, \vec{y})}\,, \\
    \tan \angle(\vec{x}, \vec{y}) &\coloneqq
                                    \frac{
                                    \sin \angle(\vec{x}, \vec{y})
                                    }{
                                    \cos \angle(\vec{x}, \vec{y})
                                    }\,.
  \end{align*}
\end{definition}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../main"
%%% End:
