\chapter{Proofs}\label{appendix:proofs}
\begin{proof}[Proof of Lemma~\ref{lem:eigs:atilde0}]
  First consider $j \neq k$. Using the orthogonality of the
  eigenvectors we have $\vec{v}_k^\tp \vec{v}_j = 0$ and thus
  \begin{align*}
    (\mat{A} - i \gamma(\mat{I}- \vec{v}_k \vec{v}_k^\tp)) \vec{v}_j &= \mat{A}\vec{v}_j - i \gamma \vec{v}_j + i \gamma \vec{v}_k \vec{v}_k^\tp  \vec{v}_j \\
                                                                     &= \lambda_j \vec{v}_j - i \gamma \vec{v}_j \\
                                                                     &= (\lambda_j - i \gamma) \vec{v}_j \,.   
  \end{align*}
  For $j = k$ we have
  $\vec{v}_k^\tp \vec{v}_j = \vec{v}_k^\tp \vec{v}_k = 1$ and thus
  \begin{equation*}
    (\mat{A} - i \gamma(\mat{I}- \vec{v}_k \vec{v}_k^\tp)) \vec{v}_k = \lambda_k \vec{v}_k - i \gamma \vec{v}_k + i \gamma \vec{v}_k = \lambda_k \vec{v}_k\,.
  \end{equation*}
\end{proof}

\begin{proof}[Proof of Lemma~\ref{lem:eigs:atilde1}]
  Since
  \begin{equation*}
    \norm{\tilde{\mat{A}}_{(1)}} = \norm{i \gamma \left( \vec{u} \vec{u}^\tp - \vec{v}_k \vec{v}_k^\tp \right)} = \gamma \norm{\smash{\underbrace{
          \vec{u} \vec{u}^\tp - \vec{v}_k \vec{v}_k^\tp
        }_{\eqqcolon \mat{E}}}
    }
  \end{equation*}
  it suffices to compute the norm of $\mat{E}$. Additionally,
  $\mat{E}$ is symmetric (since it is a sum of two symmetric matrices)
  and thus its spectral norm coincides with its spectral radius. The
  matrices $\vec{u}\vec{u}^\tp$ and $\vec{v}_k\vec{v}_k^\tp$ have both
  rank one and therefore $\mat{E}$ is at most of rank two. This
  implies that it has at most two non-zero eigenvalues, denoted by
  $\mu_1$ and $\mu_2$, and we can therefore compute both of them and
  take the one that is larger in modulus.

  To compute the eigenvalues of $\mat{E}$ we use the following two
  well-known facts from linear algebra. Here, $\tr(\mat{E}) $ denotes
  the trace of $\mat{E}$ defined as the sum of the diagonal entries of
  the matrix.
  \begin{enumerate}
  \item The trace is the sum of the eigenvalues of $\mat{E}$,
    \ie\todo{eigenvalues * algebraic multiplicity}
    \begin{equation}
      \label{eq:trace:sumeigenvalues}
      \tr(\mat{E}) = \mu_1 + \mu_2\,.
    \end{equation}
  \item The eigenvalues of the square of $\mat{E}$ are $\mu_1^2$ and
    $\mu_2^2$ and thus, using the previous fact,
    \begin{equation}
      \label{eq:trace:sumeigenvalues:square}
      \tr(\mat{E}^2) = \mu_1^2 + \mu_2^2 \,.
    \end{equation}
  \end{enumerate}
  The diagonal entries of the matrices $\vec{u}\vec{u}^\tp$ and
  $\vec{v}_k\vec{v}_k^\tp$ consist of the squares of their respective
  entries and thus, using the additivity of the trace and the fact
  that both vectors are assumed to be normalised, we get
  \begin{equation*}
    \tr(\mat{E}) = \norm*{\vec{u}} - \norm*{\vec{v}_k} = 0
  \end{equation*}
  which in conjunction with~\eqref{eq:trace:sumeigenvalues} implies
  $\mu_1 = -\mu_2$.  We expand $\mat{E}^2$ and obtain
  \begin{align*}
    \mat{E}^2 &= (\vec{u} \vec{u}^\tp - \vec{v}_k \vec{v}_k^\tp)(\vec{u} \vec{u}^\tp - \vec{v}_k \vec{v}_k^\tp) \\
              &= \vec{u}\vec{u}^\tp\vec{u}\vec{u}^\tp
                - \vec{v}_k\vec{v}_k^\tp\vec{u}\vec{u}^\tp
                - \vec{u}\vec{u}^\tp\vec{v_k}\vec{v_k}^\tp
                + \vec{v}_k\vec{v}_k^\tp\vec{v}_k\vec{v}_k^\tp \\
              &= \vec{u}\vec{u}^\tp + \vec{v}_k \vec{v}_k^\tp - \langle \vec{u}, \vec{v}_k \rangle \left(\vec{u}\vec{v}_k^\tp + \vec{v}_k\vec{u}^\tp\right)\,.
  \end{align*}
  Therefore,
  \begin{align*}
    \tr(\mat{E}^2) &= \norm*{\vec{u}} + \norm*{\vec{v}_k} - \langle \vec{u}, \vec{v}_k \rangle
                     (\langle \vec{u}, \vec{v}_k \rangle + \langle \vec{u}, \vec{v}_k \rangle) \\
                   &= 2 - 2{\langle \vec{u}, \vec{v}_k \rangle}^2\,.
  \end{align*}
  However, we also have $\tr(\mat{E}^2) = 2\mu_1^2$ due
  to~\eqref{eq:trace:sumeigenvalues:square} and so
  \begin{equation*}
    \mu_1 = \sqrt{1 - {\langle \vec{u}, \vec{v}_k \rangle}^2}
  \end{equation*}
  from which the result follows.
\end{proof}

\begin{proof}[Proof of Proposition~\ref{prop:atilde:eigenvalues}]
  For this proof we treat $\tilde{\mat{A}}_{(1)}$ as a perturbation of
  $\tilde{\mat{A}}_{(0)}$ and a result from~\cite{REFERENCE} which
  states that the eigenvalues of
  $\tilde{\mat{A}} = \tilde{\mat{A}}_{(0)} + \tilde{\mat{A}}_{(1)}$
  satisfy
  \begin{equation}%
    \label{eq:eigval:estimation}
    \lambda_j(\tilde{\mat{A}}) = \lambda_j(\tilde{\mat{A}}_{(0)})
    +
    \vec{w}_j^\herm \tilde{\mat{A}}_{(0)} \vec{w}_j + \mathcal{O}\left( \norm{\tilde{\mat{A}}_{(1)}}^2\right)\,,
  \end{equation}
  where $\vec{w}_j$ is an eigenvector belonging to
  $\lambda_j(\tilde{\mat{A}}_{(0)})$. We expand the middle part and
  obtain
  \begin{align*}
    \vec{w}_j^\herm \tilde{\mat{A}}_{(0)} \vec{w}_j &= i \gamma \vec{w}_j^\herm  \left( \vec{u}\vec{u}^\herm - \vec{v}_k \vec{v}_k^\herm  \right) \vec{w}_j \\
                                                    &= i \gamma \left( \vec{w}_j^\herm\vec{u}\vec{u}^\herm\vec{w}_j - \vec{w}_j^\herm\vec{v}_k\vec{v}_k^\herm\vec{w}_j\right) \\
                                                    &= i \gamma \left({\langle \vec{w}_j, \vec{u}\rangle}^2 - {\langle \vec{w}_j, \vec{v}_k\rangle}^2 \right) \\
                                                    &=
                                                      \begin{cases}
                                                        i \gamma {\langle \vec{v}_j, \vec{u}\rangle}^2 & \text{ if } j \neq k\,, \\
                                                        i \gamma
                                                        \left(
                                                          {\langle
                                                            \vec{v}_j,
                                                            \vec{u}\rangle}^2
                                                          - 1 \right)
                                                        & \text{ if }
                                                        j = k\,,
                                                      \end{cases}
  \end{align*}
  where we used Lemma~\ref{lem:eigs:atilde0} in the last step, which
  states that in fact $\vec{w}_j = \vec{v}_j$ with $\vec{v}_j$ being
  the eigenvectors of $\mat{A}$. Adding this to the first part
  of~\eqref{eq:eigval:estimation} yields
  \begin{align*}
    \lambda_j(\tilde{\mat{A}}_{(0)})
    +
    \vec{w}_j^\herm \tilde{\mat{A}}_{(0)} \vec{w}_j
    &=
      \lambda_j(\mat{A}) - i \gamma + i \gamma {\langle \vec{v}_j, \vec{u}\rangle}^2 \\
    &=
      \lambda_j(\mat{A}) + i \gamma \left( {\langle \vec{v}_j, \vec{u}\rangle}^2 - 1 \right)
  \end{align*}
  for $j \neq k$ and
  \begin{align*}
    \lambda_j(\tilde{\mat{A}}_{(0)})
    +
    \vec{w}_j^\herm \tilde{\mat{A}}_{(0)} \vec{w}_j
    &=
      \lambda_k(\mat{A}) + i \gamma \left( {\langle \vec{v}_k, \vec{u}\rangle}^2 - 1 \right)
  \end{align*}
  for $j = k$ and thus
  \begin{equation*}
    \lambda_j(\tilde{\mat{A}}) =
    \lambda_j(\mat{A}) + i \gamma \left( {\langle \vec{v}_j, \vec{u}\rangle}^2 - 1 \right)
    + \mathcal{O}\left( \norm{\tilde{\mat{A}}_{(1)}}^2\right)\,,
  \end{equation*}
  for all $j = 1, \dotsc, n$, which concludes the proof.
\end{proof}
% \begin{lemma}[Sherman-Morrison formula in the complex case]
%   Let $\mat{A} \in \C^{n \times n}$ be invertible. Let
%   $\vec{u}, \vec{v} \in \C^n$ be vectors. If
%   $1 + \vec{v}^\herm \mat{A}^{-1}\vec{u} \neq 0$ then
%   $\mat{A} + \vec{u}\vec{v}^\herm$ is invertible with
%   \begin{equation}%
%     \label{eq:smf}
%     {\left( \mat{A} + \vec{u}\vec{v}^\herm \right)}^{-1} = \mat{A}^{-1} +
%     \frac{
%       \mat{A}^{-1} \vec{u} \vec{v}^\herm \mat{A}^{-1}
%     }{
%       1 + \vec{v}^\herm \mat{A}^{-1} \vec{u}
%     }\,.
%   \end{equation}
% \end{lemma}
% \begin{proof}
%   Denote by $\mat{X}$ the left hand side of~\eqref{eq:smf} and by
%   $\mat{Y}$ the right hand side of the equation. We have to verify
%   $\mat{X}\mat{Y} = \mat{I} = \mat{Y}\mat{X}$.
%   \begin{align*}
%     \mat{X}\mat{Y} &= \left(
%                      \mat{A} + \vec{u}\vec{v}^\herm
%                      \right)
%                      \left(
%                      \mat{A}^{-1} - \frac{
%                      \mat{A}^{-1} \vec{u} \vec{v}^\herm \mat{A}^{-1}
%                      }{
%                      1 + \vec{v}^\herm \mat{A}^{-1} \vec{u}
%                      }
%                      \right) \\
%                    &= \mat{A}\mat{A}^{-1} + \vec{u}\vec{v}^\herm\mat{A}^{-1}
%                      - \frac{
%                      \mat{A}\mat{A}^{-1} \vec{u}\vec{v}^\herm\mat{A}^{-1} + \vec{u}\vec{v}^\herm\mat{A}^{-1}\vec{u}\vec{v}^\herm\mat{A}^{-1}
%                      }{
%                      1 + \vec{v}^\herm \mat{A}^{-1} \vec{u}
%                      } \\
%                    &= \mat{I} + \vec{u}\vec{v}^\herm \mat{A}^{-1}
%                      - \frac{
%                      \vec{u}\left( 1 + \vec{v}^\herm \mat{A}^{-1} \vec{u} \right) \vec{v}^\herm \mat{A}^{-1}
%                      }{
%                      1 + \vec{v}^\herm \mat{A}^{-1} \vec{u}
%                      } \\
%                    &= \mat{I} + \vec{u}\vec{v}^\herm \mat{A}^{-1} - \vec{u}\vec{v}^\herm \mat{A}^{-1} = \mat{I}\,.
%   \end{align*}
%   Similarly
%   \begin{align*}
%     \mat{Y}\mat{X} &=\left(
%                      \mat{A}^{-1} - \frac{
%                      \mat{A}^{-1} \vec{u} \vec{v}^\herm \mat{A}^{-1}
%                      }{
%                      1 + \vec{v}^\herm \mat{A}^{-1} \vec{u}
%                      }
%                      \right)
%                      \left(
%                      \mat{A} + \vec{u}\vec{v}^\herm
%                      \right) \\
%                    &= \mat{A}^{-1} \mat{A} + \mat{A}^{-1}\vec{u}\vec{v}^\herm
%                      - \frac{
%                      \mat{A}^{-1}\vec{u}\vec{v}^\herm \mat{A}^{-1} \mat{A} + \mat{A}^{-1} \vec{u} \vec{v}^\herm \mat{A}^{-1} \vec{u} \vec{v}^\herm
%                      }{
%                      1 + \vec{v}^\herm \mat{A}^{-1} \vec{u}
%                      } \\
%                    &= \mat{I} + \mat{A}^{-1} \vec{u}\vec{v}^\herm
%                      -\frac{
%                      \mat{A}^{-1} \vec{u} (1 + \vec{v}^\herm \mat{A}^{-1} \vec{u})\vec{v}^\herm
%                      }{
%                      1 + \vec{v}^\herm \mat{A}^{-1} \vec{u}
%                      }\\
%                    &= \mat{I} + \mat{A}^{-1}\vec{u}\vec{v}^\herm - \mat{A}^{-1}\vec{u}\vec{v}^\herm = \mat{I}\,,                     
%   \end{align*}
%   which concludes the proof.
% \end{proof}

% \begin{proof}[Proof of Lemma~\ref{lem:rq:quadestimate}]
%   This proof is due to BÃ¶rm~\cite[70]{boerm}.

%   Let $\alpha \in \C$. By using Lemma~\ref{lem:rq:properties} (ii)
%   we obtain
%   \begin{align*}
%     \abs{\rq_{\mat{A}}(\vec{x}) - \lambda}
%     &=
%       \abs{\rq_{\mat{A} - \lambda \mat{I}}(\vec{x})}\\
%     &=
%       \abs{
%       \frac{\langle \vec{x}, (\mat{A} - \lambda \mat{I}) \vec{x} \rangle}{\langle \vec{x}, \vec{x} \rangle}
%       }\\
%     &=
%       \frac{
%       \abs{
%       \langle \vec{x}, (\mat{A} - \lambda \mat{I})(\vec{x} - \alpha \vec{v}) \rangle
%       }
%       }{
%       \norm{x}^2
%       }
%     \\
%     &=
%       \frac{
%       \abs{
%       \langle {(\mat{A} - \lambda \mat{I})}^\ast \vec{x}, \vec{x} - \alpha \vec{v} \rangle
%       }
%       }{
%       \norm{x}^2
%       }
%     \\
%     &= 
%       \frac{
%       \abs{
%       \langle {(\mat{A} - \lambda \mat{I})}^\ast(\vec{x} - \alpha \vec{v}), \vec{x} - \alpha \vec{v} \rangle
%       }
%       }{
%       \norm{x}^2
%       }
%     \\
%     &=
%       \frac{
%       \abs{
%       \langle {\vec{x} - \alpha \vec{v}, (\mat{A} - \lambda \mat{I})} (\vec{x} - \alpha \vec{v}) \rangle
%       }
%       }{
%       \norm{x}^2
%       }
%     \\
%     &\le
%       \frac{
%       \norm{\vec{x} - \alpha \vec{v}} \norm{\mat{A} - \lambda \mat{I}} \norm{\vec{x} - \alpha \vec{v}}
%       }{
%       \norm{\vec{x}}^2
%       }
%     \\
%     &=
%       \norm{\mat{A} - \lambda \mat{I}} {\left(
%       \frac{
%       \norm{\vec{x} - \alpha \vec{v}}
%       }{
%       \norm{\vec{x}}
%       }
%       \right)}^2
%   \end{align*}
% \end{proof}
% \todo{Finish proof (maybe in appendix?)}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../main"
%%% End:

